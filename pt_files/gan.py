import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torchvision.datasets import ImageFolder
from torch.utils.data import DataLoader
from torch.nn.utils import spectral_norm

class Discriminator(nn.Module):
    '''
    The Discriminator that shall distinguish between dataset images and the ones generated by the generator.
    '''
    def __init__(self, number_of_gpus):
        super(Discriminator, self).__init__()
        self.ngpu = number_of_gpus
        
        self.layer1 = nn.Sequential(
            spectral_norm(nn.Conv2d(in_channels=3, out_channels=discriminator_depth, 
                                    kernel_size=(2, 2), stride=2, padding=1, bias=False)),
            nn.LeakyReLU(0.2, inplace=True)
        )
        
        self.layer2 = nn.Sequential(
            spectral_norm(nn.Conv2d(in_channels=discriminator_depth, out_channels=discriminator_depth*2, 
                                    kernel_size=(2, 2), stride=2, padding=1, bias=False)),
            nn.BatchNorm2d(discriminator_depth*2),
            nn.LeakyReLU(0.2, inplace=True)
        )
        
        self.layer3 = nn.Sequential(
            spectral_norm(nn.Conv2d(in_channels=discriminator_depth*2, out_channels=discriminator_depth*4, 
                                    kernel_size=(2, 2), stride=2, padding=1, bias=False)),
            nn.BatchNorm2d(discriminator_depth*4),
            nn.LeakyReLU(0.2, inplace=True)
        )
        
        self.layer4 = nn.Sequential(
            spectral_norm(nn.Conv2d(in_channels=discriminator_depth*4, out_channels=discriminator_depth*8, 
                                    kernel_size=(2, 2), stride=2, padding=1, bias=False)),
            nn.BatchNorm2d(discriminator_depth*8),
            nn.LeakyReLU(0.2, inplace=True)
        )
        
        self.layer5 = nn.Sequential(
            spectral_norm(nn.Conv2d(in_channels=discriminator_depth*8, out_channels=discriminator_depth*16, 
                                    kernel_size=(2, 2), stride=2, padding=1, bias=False)),
            nn.BatchNorm2d(discriminator_depth*16),
            nn.LeakyReLU(0.2, inplace=True)
        )
        
        self.output_layer = nn.Sequential(
            nn.Conv2d(in_channels=discriminator_depth*16, out_channels=1, 
                                    kernel_size=(2, 2), stride=1, padding=0, bias=False),
            nn.Sigmoid()
        )


    def forward(self, input_image):
    
        layer1 = self.layer1(input_image)
        layer2 = self.layer2(layer1)
        layer3 = self.layer3(layer2)
        layer4 = self.layer4(layer3)
        layer5 = self.layer5(layer4)
        return self.output_layer(layer5)


class Generator(nn.Module):
    '''
    The Generator Network. It is mostly a reversed discriminator with a random input noise which outputs an image.
    '''
    def __init__(self, number_of_gpus):
        super(Generator, self).__init__()
        self.ngpu = number_of_gpus
        
        self.layer1 = nn.Sequential(
            nn.ConvTranspose2d(in_channels=100, out_channels=generator_depth*16, 
                               kernel_size=(4,4), stride=1, padding=0, bias=False),
            nn.BatchNorm2d(num_features=generator_depth*16),
            nn.ReLU(inplace=True)
        )

        self.layer2 = nn.Sequential(
            nn.ConvTranspose2d(in_channels=generator_depth*16, out_channels=generator_depth*8, 
                               kernel_size=(4,4), stride=2, padding=1, bias=False),
            nn.BatchNorm2d(num_features=generator_depth*8),
            nn.ReLU(inplace=True)
        )
        
        self.layer3 = nn.Sequential(
            nn.ConvTranspose2d(in_channels=generator_depth*8, out_channels=generator_depth*4, 
                               kernel_size=(4,4), stride=2, padding=1, bias=False),
            nn.BatchNorm2d(num_features=generator_depth*4),
            nn.ReLU(inplace=True)
        )
            
        self.layer4 = nn.Sequential(
            nn.ConvTranspose2d(in_channels=generator_depth*4, out_channels=generator_depth*2, 
                               kernel_size=(4,4), stride=2, padding=1, bias=False),
            nn.BatchNorm2d(num_features=generator_depth*2),
            nn.ReLU(inplace=True)
        )
        
        self.layer5 = nn.Sequential(
            nn.ConvTranspose2d(in_channels=generator_depth*2, out_channels=generator_depth, 
                               kernel_size=(4,4), stride=2, padding=1, bias=False),
            nn.BatchNorm2d(num_features=generator_depth),
            nn.ReLU(inplace=True)
        )
        
        self.output_layer = nn.Sequential(
            nn.ConvTranspose2d(in_channels=generator_depth, out_channels=3, 
                               kernel_size=(4,4), stride=2, padding=1, bias=False),
            nn.Tanh()
        )
        

    def forward(self, input_noise):
        
        layer1 = self.layer1(input_noise)
        layer2 = self.layer2(layer1)
        layer3 = self.layer3(layer2)
        layer4 = self.layer4(layer3)
        layer5 = self.layer5(layer4)
        return self.output_layer(layer5)

# Define hyperparameters
batch_size = 16  
generator_depth = 64
discriminator_depth = 128 
loss_function = nn.BCELoss()
number_of_epochs = 10

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define transforms for image preprocessing
transform = transforms.Compose([
    transforms.Resize((48, 48)),
    transforms.Grayscale(num_output_channels=3),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize grayscale values to -1 to 1
])

# Define dataset and dataloader
dataset = ImageFolder(root = '/data/eurova/fer/train/', transform = transform)
dataloader = DataLoader(dataset, batch_size = batch_size, shuffle = True)

# Instantiate the Discriminator and Generator
discriminator = Discriminator(number_of_gpus = 0).to(device)
generator = Generator(number_of_gpus = 0).to(device)
discriminator_optimizer = optim.Adam(discriminator.parameters(), lr = 0.0001, betas = (0.5, 0.999))
generator_optimizer = optim.Adam(generator.parameters(), lr = 0.0001, betas = (0.5, 0.999))


for epoch in range(number_of_epochs):
    print(epoch)
    for batch, _ in dataloader:
        batch = batch.to(device)
        
        discriminator.zero_grad()
        
        # Prediction and loss for real dataset images
        prediction_real = discriminator(batch)  # Prediction for real dataset images
        labels_real = torch.ones_like(prediction_real, device=device)
        loss_discriminator_real = loss_function(prediction_real.view(-1), labels_real.view(-1))
        loss_discriminator_real.backward()

        # Generate images and compute prediction and loss for generated images
        random_noise = torch.randn(batch.size(0), 100, 1, 1, device=device)
        generated_image = generator(random_noise)

        prediction_fake = discriminator(generated_image.detach())  # Prediction for generated images
        labels_fake = torch.zeros_like(prediction_fake, device=device)
        loss_discriminator_fake = loss_function(prediction_fake.view(-1), labels_fake.view(-1))
        loss_discriminator_fake.backward()

        # Update discriminator's parameters
        discriminator_optimizer.step()

        # Train the generator
        generator.zero_grad()

        prediction_generator = discriminator(generated_image)
        labels_generator = torch.ones_like(prediction_generator, device=device)  # Fool the discriminator
        loss_generator = loss_function(prediction_generator.view(-1), labels_generator.view(-1))
        loss_generator.backward()

        # Update generator's parameters
        generator_optimizer.step()
    
    # Compute and print discriminator and generator losses at the end of each epoch
    print(f"Epoch [{epoch+1}/{number_of_epochs}] - Discriminator Loss (real): {loss_discriminator_real.item():.4f} - Generator Loss: {loss_generator.item():.4f}")


def euclidean_distance(a, b):
    '''
    Calculates the euklidean Distance of two torch tensors of the same size.
    '''
    return torch.sqrt(((a - b) ** 2).sum())


def get_k_nearest_samples(image, k):
    '''
    Searches for the k-nearest samples in the dataset of a given image based on the euclidean distance.
    '''
    return np.argsort([euclidean_distance(image[0][0], sample[0][0]) for sample in dataset])[:k]